---
title: "stat_learning"
author: "rl3411"
date: "2023-12-07"
output: github_document
---


```{r}
library(tidyverse)
library(glmnet)
set.seed(11)
```

## Lasso

Useful when we have many covariates

```{r}
bwt_df = 
  read_csv("data/birthweight.csv") |> 
  janitor::clean_names() |>
  mutate(
    babysex = as.factor(babysex),
    babysex = fct_recode(babysex, "male" = "1", "female" = "2"),
    frace = as.factor(frace),
    frace = fct_recode(
      frace, "white" = "1", "black" = "2", "asian" = "3", 
      "puerto rican" = "4", "other" = "8"),
    malform = as.logical(malform),
    mrace = as.factor(mrace),
    mrace = fct_recode(
      mrace, "white" = "1", "black" = "2", "asian" = "3", 
      "puerto rican" = "4")) |> 
  sample_n(200)
```


Get predictors and outcome

```{r}
# set the design matrix

x = model.matrix(bwt ~ ., bwt_df)[, -1]
y = bwt_df |> pull(bwt)
```

Start fitting lasso.

```{r}
lambda = 10^(seq(3,-2, -0.1))

lasso_fit = 
  glmnet(x, y, lambda = lambda) # if we don't specify lambda, glmnet will do it for you (or try to)

lasso_cv = 
  cv.glmnet(x, y, lambda = lambda)

lambda_opt = lasso_cv$lambda.min
```

Let's look at lasso results

```{r}
lasso_fit |> 
  broom::tidy() |> 
  filter(step == 42)
```

Create visualizations for regression

```{r}
lasso_fit |> 
  broom::tidy() |> 
  select(term, lambda, estimate) |> 
  complete(term, lambda, fill = list(estimate = 0)) |> 
  filter(term != "(Intercept)")  |> 
  ggplot(aes(x = log(lambda,10), y = estimate, color = term, group = term)) +
  geom_path()
```

Show the CV results

```{r}
lasso_cv |> 
  broom::tidy() |> 
  ggplot(aes(x = log(lambda, 10), estimate)) +
  geom_point()
```





























